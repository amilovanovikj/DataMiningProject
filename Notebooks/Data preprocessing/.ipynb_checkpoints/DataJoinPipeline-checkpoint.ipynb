{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np #Library for numerical calculations\n",
    "from scipy import stats #Library for statistical analysis \n",
    "import pandas as pd\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn\n",
    "import os\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directory_tree(tree, output_dir):\n",
    "    \"\"\"\n",
    "    Create the output directory tree structure specified by `tree` in `output_dir`\n",
    "\n",
    "    Parameters\n",
    "    -----\n",
    "    tree : list of paths to create under `output_dir`\n",
    "\n",
    "    output_dir : path to root of output directory tree\n",
    "    \"\"\"\n",
    "\n",
    "    for d in tree:\n",
    "        try:\n",
    "            path = os.path.join(output_dir, d)\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST and os.path.isdir(path):\n",
    "                print(\"Path already exists: {}\".format(d))\n",
    "                print(\"Files may be overwritten\")\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "def combine_reports(files_to_combine, outpath, is_mat=False,is_train=True):\n",
    "    \"\"\"\n",
    "    Produce a combined file from all the input files and saves it in outpath\n",
    "\n",
    "    Parameters\n",
    "    -----\n",
    "    files_to_combine : data of same type\n",
    "\n",
    "    outpath : path at which to save the combined dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    if outpath.endswith(\".txt\"):\n",
    "        outpath = outpath.replace(\".txt\",\".csv\")\n",
    "        \n",
    "    print(\"Creating file: \",outpath)\n",
    "    \n",
    "    if is_mat:\n",
    "        if is_train:\n",
    "            arrays = tuple([scipy.io.loadmat(file)['trainData'] for file in files_to_combine])\n",
    "            merged_array = np.concatenate(arrays,axis=-1)\n",
    "            matlab_dict = {'trainData':merged_array}\n",
    "        else:\n",
    "            arrays = tuple([scipy.io.loadmat(file)['testData'] for file in files_to_combine])\n",
    "            merged_array = np.concatenate(arrays,axis=-1)\n",
    "            matlab_dict = {'testData':merged_array}\n",
    "            \n",
    "        scipy.io.savemat(outpath,matlab_dict)\n",
    "        \n",
    "    else:\n",
    "        dfs = [pd.read_csv(file,header=None) for file in files_to_combine]\n",
    "        df = pd.concat(dfs,ignore_index=True)\n",
    "        df.columns=['Values']\n",
    "        df.to_csv(outpath,index=False)\n",
    "\n",
    "\n",
    "def get_datasets(data_dir):\n",
    "    \"\"\"\n",
    "    Get all filenames from the specified directory\n",
    "\n",
    "    Parameters\n",
    "    -----\n",
    "    data_dir : path to directory containing the files\n",
    "\n",
    "    Returns\n",
    "    -----\n",
    "    ret : list containing dataset filenames\n",
    "    \"\"\"\n",
    "\n",
    "    return [f for f in os.listdir(data_dir) if os.path.isfile(\n",
    "        os.path.join(data_dir, f)) and (f.endswith(\".txt\") or f.endswith(\".mat\"))]   \n",
    "\n",
    "\n",
    "def run_data_aggregation(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Iterate over the input directories and generate the new aggregated files in the output_dir\n",
    "\n",
    "    Parameters\n",
    "    -----\n",
    "    input_dir : path to directory containing input data\n",
    "    \n",
    "    output_dir : output directory for storing processed data\n",
    "\n",
    "    \"\"\"\n",
    "    number_of_subjects=15\n",
    "    subject_names = [\"SBJ\"+str(i).zfill(2) for i in range(1,number_of_subjects+1)]\n",
    "    number_of_sessions = 3\n",
    "    session_names = [\"S\"+str(i).zfill(2) for i in range(1,number_of_sessions+1)]\n",
    "    train_files = get_datasets(os.path.join(input_dir,\"SBJ01/S01/Train\"))\n",
    "    test_files = get_datasets(os.path.join(input_dir,\"SBJ01/S01/Test\"))\n",
    "    \n",
    "    #Creating folders for each subject\n",
    "    make_directory_tree(subject_names,output_dir)\n",
    "    for subject_no in range(number_of_subjects):\n",
    "        trainEvents=[]\n",
    "        trainLabels=[]\n",
    "        trainTargets=[]\n",
    "        trainData=[]\n",
    "        testData=[]\n",
    "        testEvents=[]\n",
    "        testRunsPerBlock=[]\n",
    "        subject_output_folder = os.path.join(output_dir,subject_names[subject_no])\n",
    "        print(\"Currently processing : \",subject_output_folder)\n",
    "        #Making train and test folders for each subject\n",
    "        make_directory_tree(['Train','Test'],subject_output_folder)\n",
    "        subject_input_folder = os.path.join(input_dir,subject_names[subject_no])\n",
    "        for session_no in range(number_of_sessions):\n",
    "            input_session_folder = os.path.join(subject_input_folder,session_names[session_no])\n",
    "            train_folder = os.path.join(input_session_folder,\"Train\")\n",
    "            test_folder = os.path.join(input_session_folder,\"Test\")\n",
    "            train_paths = [os.path.join(train_folder,train_file) for train_file in train_files]\n",
    "            test_paths = [os.path.join(test_folder,test_file) for test_file in test_files]\n",
    "\n",
    "            trainData.append(train_paths[0])\n",
    "            trainEvents.append(train_paths[1])\n",
    "            trainLabels.append(train_paths[2])\n",
    "            trainTargets.append(train_paths[3])\n",
    "            \n",
    "            testRunsPerBlock.append(test_paths[0])\n",
    "            testData.append(test_paths[1])\n",
    "            testEvents.append(test_paths[2])\n",
    "            \n",
    "        train_output_folder = os.path.join(subject_output_folder,\"Train\")\n",
    "        test_output_folder = os.path.join(subject_output_folder,\"Test\")\n",
    "        \n",
    "        combine_reports(trainData,os.path.join(train_output_folder,train_files[0]),is_mat=True)\n",
    "        combine_reports(trainEvents,os.path.join(train_output_folder,train_files[1]))\n",
    "        combine_reports(trainLabels,os.path.join(train_output_folder,train_files[2]))\n",
    "        combine_reports(trainTargets,os.path.join(train_output_folder,train_files[3]))\n",
    "        \n",
    "        combine_reports(testRunsPerBlock,os.path.join(test_output_folder,test_files[0]),is_train=False)\n",
    "        combine_reports(testData,os.path.join(test_output_folder,test_files[1]),is_mat=True,is_train=False)\n",
    "        combine_reports(testEvents,os.path.join(test_output_folder,test_files[2]),is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently processing :  medicon_data/subjects_post\\SBJ01\n",
      "Creating file:  medicon_data/subjects_post\\SBJ01\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ01\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ01\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ01\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ01\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ01\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ01\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ02\n",
      "Creating file:  medicon_data/subjects_post\\SBJ02\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ02\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ02\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ02\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ02\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ02\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ02\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ03\n",
      "Creating file:  medicon_data/subjects_post\\SBJ03\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ03\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ03\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ03\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ03\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ03\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ03\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ04\n",
      "Creating file:  medicon_data/subjects_post\\SBJ04\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ04\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ04\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ04\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ04\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ04\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ04\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ05\n",
      "Creating file:  medicon_data/subjects_post\\SBJ05\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ05\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ05\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ05\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ05\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ05\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ05\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ06\n",
      "Creating file:  medicon_data/subjects_post\\SBJ06\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ06\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ06\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ06\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ06\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ06\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ06\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ07\n",
      "Creating file:  medicon_data/subjects_post\\SBJ07\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ07\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ07\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ07\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ07\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ07\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ07\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ08\n",
      "Creating file:  medicon_data/subjects_post\\SBJ08\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ08\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ08\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ08\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ08\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ08\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ08\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ09\n",
      "Creating file:  medicon_data/subjects_post\\SBJ09\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ09\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ09\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ09\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ09\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ09\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ09\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ10\n",
      "Creating file:  medicon_data/subjects_post\\SBJ10\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ10\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ10\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ10\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ10\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ10\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ10\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ11\n",
      "Creating file:  medicon_data/subjects_post\\SBJ11\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ11\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ11\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ11\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ11\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ11\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ11\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ12\n",
      "Creating file:  medicon_data/subjects_post\\SBJ12\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ12\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ12\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ12\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ12\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ12\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ12\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ13\n",
      "Creating file:  medicon_data/subjects_post\\SBJ13\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ13\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ13\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ13\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ13\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ13\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ13\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ14\n",
      "Creating file:  medicon_data/subjects_post\\SBJ14\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ14\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ14\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ14\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ14\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ14\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ14\\Test\\testEvents.csv\n",
      "Currently processing :  medicon_data/subjects_post\\SBJ15\n",
      "Creating file:  medicon_data/subjects_post\\SBJ15\\Train\\trainData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ15\\Train\\trainEvents.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ15\\Train\\trainLabels.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ15\\Train\\trainTargets.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ15\\Test\\runs_per_block.csv\n",
      "Creating file:  medicon_data/subjects_post\\SBJ15\\Test\\testData.mat\n",
      "Creating file:  medicon_data/subjects_post\\SBJ15\\Test\\testEvents.csv\n"
     ]
    }
   ],
   "source": [
    "run_data_aggregation(\"medicon_data/subjects_pre\", \"medicon_data/subjects_post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old mat train file shape:  (8, 350, 1600)\n",
      "Old train events shape:  (1600, 1)\n",
      "Old train labels shape:  (20, 1)\n",
      "Old train targets shape:  (1600, 1)\n",
      "New mat train file shape:  (8, 350, 4800)\n",
      "New train events shape:  (4800, 1)\n",
      "New train labels shape:  (60, 1)\n",
      "New train targets shape:  (4800, 1)\n"
     ]
    }
   ],
   "source": [
    "#Testing mat train file (1 session vs all 3 sessions shapes). New files should be 3 times the size:\n",
    "old_train_folder = \"medicon_data/subjects_pre/SBJ01/S01/Train\"\n",
    "\n",
    "mat = scipy.io.loadmat(os.path.join(old_train_folder,\"trainData\"))\n",
    "data = mat['trainData']\n",
    "print(\"Old mat train file shape: \",data.shape)\n",
    "\n",
    "train_events = pd.read_csv(os.path.join(old_train_folder,\"trainEvents.txt\"),header=None)\n",
    "print(\"Old train events shape: \",train_events.shape)\n",
    "\n",
    "train_labels = pd.read_csv(os.path.join(old_train_folder,\"trainLabels.txt\"),header=None)\n",
    "print(\"Old train labels shape: \",train_labels.shape)\n",
    "\n",
    "train_targets = pd.read_csv(os.path.join(old_train_folder,\"trainTargets.txt\"),header=None)\n",
    "print(\"Old train targets shape: \",train_targets.shape)\n",
    "\n",
    "new_train_folder = \"medicon_data/subjects_post/SBJ01/Train\"\n",
    "\n",
    "mat = scipy.io.loadmat(os.path.join(new_train_folder,\"trainData\"))\n",
    "data = mat['trainData']\n",
    "print(\"New mat train file shape: \",data.shape)\n",
    "\n",
    "train_events = pd.read_csv(os.path.join(new_train_folder,\"trainEvents.csv\"))\n",
    "print(\"New train events shape: \",train_events.shape)\n",
    "\n",
    "train_labels = pd.read_csv(os.path.join(new_train_folder,\"trainLabels.csv\"))\n",
    "print(\"New train labels shape: \",train_labels.shape)\n",
    "\n",
    "train_targets = pd.read_csv(os.path.join(new_train_folder,\"trainTargets.csv\"))\n",
    "print(\"New train targets shape: \",train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Values\n",
      "0          7\n",
      "1          3\n",
      "2          4\n",
      "3          1\n",
      "4          6\n",
      "...      ...\n",
      "4795       6\n",
      "4796       7\n",
      "4797       2\n",
      "4798       5\n",
      "4799       3\n",
      "\n",
      "[4800 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
